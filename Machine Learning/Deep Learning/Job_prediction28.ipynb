{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3661bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QFont::fromString: Invalid description 'Noto Sans,11,-1,5,700,0,0,0,0,0,0,0,0,0,0,1,Bold'\n",
      "QFont::fromString: Invalid description 'Noto Sans,11,-1,5,700,0,0,0,0,0,0,0,0,0,0,1,Bold'\n",
      "QFont::fromString: Invalid description 'Noto Sans,11,-1,5,700,0,0,0,0,0,0,0,0,0,0,1,Bold'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib qt5\n",
    "torch.set_num_interop_threads(8)\n",
    "torch.set_num_threads(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de93736",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=optim.Adam(model.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655177f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model =nn.Sequential(nn.Linear(1,64),\n",
    "                     nn.Tanh(),\n",
    "                     nn.Linear(64,1))\n",
    "loss=nn.MSELoss()\n",
    "optimizer=optim.AdamW(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9307e0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.linspace(1,100,5000)\n",
    "noise=np.random.normal(0,1,size=X.shape)\n",
    "Y_actual=np.sin(X)\n",
    "tx=torch.from_numpy(X.astype(np.float32)).view(-1,1)\n",
    "yx=torch.from_numpy(Y_actual.astype(np.float32)).view(-1,1)\n",
    "fig,axes=plt.subplots()\n",
    "b=axes.plot([0],[0],color=\"blue\")\n",
    "try:\n",
    "    lossy\n",
    "except:\n",
    "    lossy=[]\n",
    "for i in range(100000):\n",
    "    y_pred=model(tx)\n",
    "    lossval=loss(y_pred,yx)\n",
    "    optimizer.zero_grad()\n",
    "    lossval.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "    print(f'{i+1} epoch with loss {lossval.item()}')\n",
    "    if (i+1)%1000==0:\n",
    "        lossy.append(lossval.item())\n",
    "        b[0].set_xdata(np.arange(len(lossy))*1000)\n",
    "        b[0].set_ydata(lossy)\n",
    "        axes.relim()\n",
    "        axes.autoscale()\n",
    "        plt.pause(0.1)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58685bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lossy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfeec1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c297acde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55a9312",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f81383c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fadab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('/home/user456/CommonRuntime/python ML/breast-cancer.csv')\n",
    "y=df['diagnosis'].to_numpy()\n",
    "y=(y=='M').astype(np.int16)\n",
    "y=y.reshape(-1,1)\n",
    "X=df.drop(columns=['id','diagnosis']).to_numpy()\n",
    "print(X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8e14b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logistic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear=nn.Linear(30,1)\n",
    "        self.ReLU=nn.ReLU()\n",
    "        self.out=nn.Linear(64,1)\n",
    "    def forward(self,x):\n",
    "        out=self.linear(x)\n",
    "        return out\n",
    "    \n",
    "loss=nn.BCEWithLogitsLoss()\n",
    "model=Logistic()\n",
    "optimizer=optim.AdamW(model.parameters(),lr=3*1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c35bb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tx=torch.from_numpy(X.astype(np.float32))\n",
    "ty=torch.from_numpy(y.astype(np.float32))\n",
    "\n",
    "for i in range(50000):\n",
    "    y_pred=model(tx)\n",
    "    lossval=loss(y_pred,ty)\n",
    "    optimizer.zero_grad()\n",
    "    lossval.backward()\n",
    "    optimizer.step()\n",
    "    if (i+1)%1000==0:\n",
    "        print(f'{i+1} epoch with loss {lossval.item()}')\n",
    "with torch.no_grad():\n",
    "    y_pred=model(tx)\n",
    "    predicted=torch.sigmoid(y_pred)\n",
    "    predicted_cls=(predicted>=0.5).to(torch.int16)\n",
    "    print(predicted_cls)\n",
    "    accuracy=(predicted_cls==ty).sum().item()/len(ty)\n",
    "    print(f'Accuracy is {accuracy}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7d7089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2c19a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64f85e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  educational-num  hours-per-week  income_>50K  workclass_id  \\\n",
      "0   67               16              60            1             0   \n",
      "1   17                8              15            0             0   \n",
      "2   31               13              40            1             0   \n",
      "3   58                4              40            0             1   \n",
      "4   25               10              40            0             1   \n",
      "\n",
      "   marital-status_id  occupation_id  relationship_id  race_id  gender_id  \\\n",
      "0                  0              0                0        0          0   \n",
      "1                  1              1                1        0          0   \n",
      "2                  2              0                2        0          0   \n",
      "3                  2              2                2        0          0   \n",
      "4                  1              1                0        1          0   \n",
      "\n",
      "   native-country_id  \n",
      "0                  0  \n",
      "1                  0  \n",
      "2                  0  \n",
      "3                  0  \n",
      "4                  0  \n",
      "Index(['age', 'educational-num', 'hours-per-week', 'income_>50K',\n",
      "       'workclass_id', 'marital-status_id', 'occupation_id', 'relationship_id',\n",
      "       'race_id', 'gender_id', 'native-country_id'],\n",
      "      dtype='object')\n",
      "torch.Size([40727]) torch.Size([40727, 9])\n",
      "Mapping saved!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "df = pd.read_csv('/home/user456/CommonRuntime/python ML/train.csv')\n",
    "df = df.dropna()\n",
    "df = df.drop(columns=['fnlwgt','education','capital-gain','capital-loss'])\n",
    "\n",
    "cat_cols = [\n",
    "    'workclass','marital-status','occupation',\n",
    "    'relationship','race','gender','native-country'\n",
    "]\n",
    "\n",
    "mappings = {}  # to store categories\n",
    "\n",
    "for col in cat_cols:\n",
    "    codes, uniques = pd.factorize(df[col])\n",
    "    df[col + '_id'] = codes\n",
    "    mappings[col] = list(uniques)\n",
    "\n",
    "df = df.drop(columns=cat_cols)\n",
    "\n",
    "print(df.head())\n",
    "print(df.columns)\n",
    "y = torch.tensor(df['occupation_id'].values, dtype=torch.int64)\n",
    "df = df.drop(columns=['occupation_id', 'income_>50K'])\n",
    "\n",
    "x = torch.tensor(df.values, dtype=torch.float32)\n",
    "\n",
    "print(y.shape, x.shape)\n",
    "\n",
    "# persist mapping\n",
    "with open(\"cat_mappings.pkl\", \"wb\") as f:\n",
    "    pickle.dump(mappings, f)\n",
    "\n",
    "print(\"Mapping saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "09594fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "x=x.to(device)\n",
    "y=y.to(device)\n",
    "\n",
    "class CEModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(9, 256)\n",
    "        self.layer2 = nn.ReLU()\n",
    "        \n",
    "        self.layer3 = nn.Linear(256, 128)\n",
    "        self.layer4 = nn.ReLU()\n",
    "        self.drop = nn.Dropout(0)\n",
    "\n",
    "        self.layer5 = nn.Linear(128, 64)\n",
    "        self.layer6 = nn.ReLU()\n",
    "\n",
    "        self.layer7 = nn.Linear(64, 14)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.drop(out)\n",
    "\n",
    "        out = self.layer5(out)\n",
    "        out = self.layer6(out)\n",
    "\n",
    "        out = self.layer7(out)\n",
    "        return out\n",
    "\n",
    "lossy=nn.CrossEntropyLoss()\n",
    "model=CEModel()\n",
    "fig,axes=plt.subplots()\n",
    "g=axes.plot([0],[0],color=\"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d733b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=optim.AdamW(model.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fde6b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20000):\n",
    "    y_pred=model(x.float())\n",
    "    lossval=lossy(y_pred,y)\n",
    "    optimizer.zero_grad()\n",
    "    lossval.backward()\n",
    "    optimizer.step()\n",
    "    print(f'{i+1} epoch with loss {lossval.item()}')\n",
    "    if (i+1)%100==0:\n",
    "        print(f'{i+1} epoch with loss {lossval.item()}')\n",
    "        losss.append(lossval.item())\n",
    "        g[0].set_xdata(range(len(losss)))\n",
    "        g[0].set_ydata(losss)\n",
    "        axes.relim()\n",
    "        axes.autoscale_view()\n",
    "        plt.pause(0.01)\n",
    "plt.show()\n",
    "with torch.no_grad():\n",
    "    y_pred=model(x)\n",
    "    predicted_cls=torch.argmax(y_pred,dim=1)\n",
    "    accuracy=(predicted_cls==y).sum().item()/len(y)\n",
    "    print(f'Accuracy is {accuracy}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c1f846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([899]) torch.Size([899, 9])\n"
     ]
    }
   ],
   "source": [
    "with open(\"cat_mappings.pkl\", \"rb\") as f:\n",
    "    mappings = pickle.load(f)\n",
    "\n",
    "test_df = pd.read_csv(\"/home/user456/CommonRuntime/python ML/__pycache__/test.csv\")\n",
    "\n",
    "cat_cols = list(mappings.keys())\n",
    "\n",
    "for col in cat_cols:\n",
    "    mapping = {v:i for i,v in enumerate(mappings[col])}\n",
    "\n",
    "    test_df[col + \"_id\"] = test_df[col].map(mapping).fillna(-1).astype(int)\n",
    "\n",
    "test_df = test_df.drop(columns=cat_cols)\n",
    "test_df=test_df.drop(columns=['fnlwgt','education','capital-gain','capital-loss'])\n",
    "test_df\n",
    "# Target and features\n",
    "y = torch.tensor(test_df['occupation_id'].values, dtype=torch.int64)\n",
    "test_df = test_df.drop(columns=['occupation_id'])\n",
    "\n",
    "x = torch.tensor(test_df.values, dtype=torch.float32)\n",
    "\n",
    "print(y.shape, x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ca2f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CEModel(\n",
      "  (layer1): Linear(in_features=9, out_features=256, bias=True)\n",
      "  (layer2): ReLU()\n",
      "  (layer3): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (layer4): ReLU()\n",
      "  (drop): Dropout(p=0, inplace=False)\n",
      "  (layer5): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (layer6): ReLU()\n",
      "  (layer7): Linear(in_features=64, out_features=14, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "z = joblib.load(\n",
    "    '/home/user456/CommonRuntime/python ML/job_model2.pkl',  \n",
    ")\n",
    "\n",
    "model.load_state_dict(z['model'])\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c907f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 28.59%\n",
      "File saved: pred_vs_real.xlsx\n",
      "File saved: pred_vs_real.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "with open(\"cat_mappings.pkl\", \"rb\") as f:\n",
    "    mappings = pickle.load(f)\n",
    "\n",
    "occ_list = mappings[\"occupation\"]              \n",
    "occ_map_df = pd.DataFrame({\n",
    "    \"occupation_id\": range(len(occ_list)),\n",
    "    \"occupation_name\": occ_list\n",
    "})\n",
    "real_ids = y.cpu().numpy()\n",
    "pred_ids = predicted_cls.cpu().numpy()\n",
    "\n",
    "real_names = [occ_list[i] if i < len(occ_list) else \"Unknown\" for i in real_ids]\n",
    "pred_names = [occ_list[i] if i < len(occ_list) else \"Unknown\" for i in pred_ids]\n",
    "\n",
    "compare_df = pd.DataFrame({\n",
    "    \"real_occ_id\": real_ids,\n",
    "    \"real_occ_name\": real_names,\n",
    "    \"pred_occ_id\": pred_ids,\n",
    "    \"pred_occ_name\": pred_names,\n",
    "})\n",
    "\n",
    "accuracy = (predicted_cls == y).sum().item() / len(y)\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "output_path = \"pred_vs_real.xlsx\"\n",
    "with pd.ExcelWriter(output_path, engine=\"openpyxl\") as writer:\n",
    "    occ_map_df.to_excel(writer, sheet_name=\"occupation_mapping\", index=False)\n",
    "    compare_df.to_excel(writer, sheet_name=\"pred_vs_real\", index=False)\n",
    "\n",
    "print(\"File saved:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4a5ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum: 5000000050000000\n",
      "Time taken: 11.73875617980957\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
